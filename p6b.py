# -*- coding: utf-8 -*-
"""P6b.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qd5mw8u_neaE8Y0i81CsNshlxnkGk5TX

# Part 1: Generating KG

## Import Dependencies + Datasets
"""

# Commented out IPython magic to ensure Python compatibility.
import re
import pandas as pd
import bs4
import requests
import spacy
from spacy import displacy
nlp = spacy.load('en_core_web_sm')

from spacy.matcher import Matcher 
from spacy.tokens import Span 

import networkx as nx

import matplotlib.pyplot as plt
from tqdm import tqdm

pd.set_option('display.max_colwidth', 200)
# %matplotlib inline

candidate_sentences = pd.read_csv('https://raw.githubusercontent.com/phgunawan/Latihan-ML/master/wiki_sentences_v2.csv')
candidate_sentences.shape

candidate_sentences['sentence'].sample(5)

"""## Sentence Segmentation & Extraction"""

doc = nlp(candidate_sentences["sentence"][2])

for tok in doc:
  print(tok.text, "...", tok.dep_)

def get_entities(sent):
  ent1 = ""
  ent2 = ""

  prv_tok_dep = ""
  prv_tok_text = "" 

  prefix = ""
  modifier = ""

  for tok in nlp(sent):
    if tok.dep_ != "punct":
      
      # text associated with subject/object
      if tok.dep_ == "compound":
        prefix = tok.text
        if prv_tok_dep == "compound":
          prefix = prv_tok_text + " " + tok.text
      if tok.dep_.endswith("mod") == True:
        modifier = tok.text
        if prv_tok_dep == "compound":
          modifier = prv_tok_text + " " + tok.text
      
      # subject = first entity
      if tok.dep_.find("subj") == True:
        ent1 = modifier + " " + prefix + " " + tok.text
        prefix = ""
        modifier = ""
        prv_tok_dep = ""
        prv_tok_text = ""
      # object = second entity
      if tok.dep_.find("obj") == True:
        ent2 = modifier + " " + prefix + " " + tok.text

      prv_tok_dep = tok.dep_
      prv_tok_text = tok.text 
    
  return [ent1.strip(), ent2.strip()]

get_entities(candidate_sentences["sentence"][2])

entity_pairs = [] 

for i in tqdm(candidate_sentences["sentence"]):
  entity_pairs.append(get_entities(i))

entity_pairs[10:20]

# spaCy's rule-based matching
def get_relation(sent):
  doc = nlp(sent)
  matcher = Matcher(nlp.vocab)
  pattern = [{'DEP': 'ROOT'},
             {'DEP': 'prep', 'OP': '?'},
             {'DEP': 'agent', 'OP': '?'},
             {'POS': 'ADJ', 'OP': '?'}]

  matcher.add("matching_1", [pattern], on_match = None)
  matches = matcher(doc)
  k = len(matches) - 1
  try:
    span = doc[matches[k][1]:matches[k][2]]
  except:
    return "n/a"
  return span.text

get_relation(candidate_sentences["sentence"][2])

relations = [get_relation(i) for i in tqdm(candidate_sentences['sentence'])]

pd.Series(relations).value_counts()[:50]

"""## Build KG"""

source = [i[0] for i in entity_pairs]
target = [i[1] for i in entity_pairs]
kg_df = pd.DataFrame({'source': source, 'target': target, 'edge': relations, 'sentence': candidate_sentences['sentence']})

kg_df

# drop false negatives
kg_df = kg_df[kg_df.source != '']
kg_df = kg_df[kg_df.target != '']
kg_df = kg_df[kg_df.edge != 'n/a']

G = nx.from_pandas_edgelist(kg_df, 'source', 'target', edge_attr=True, create_using=nx.MultiDiGraph())

plt.figure(figsize=(12,12))

pos = nx.spring_layout(G)
nx.draw(G, with_labels=True, node_color='skyblue', edge_cmap=plt.cm.Blues, pos=pos)
plt.show()

G=nx.from_pandas_edgelist(kg_df[kg_df['edge']=='composed by'], 'source', 'target', edge_attr=True, create_using=nx.MultiDiGraph())
plt.figure(figsize=(12, 12))
pos = nx.spring_layout(G, k=0.5) # k is distance between nodes
nx.draw(G, with_labels=True, node_color='skyblue', node_size=1500, edge_cmap=plt.cm.Blues, pos=pos)
plt.show()

"""## Accuracy"""

accuracy = (kg_df.shape[0] / candidate_sentences.shape[0])
accuracy

"""#Part 2: Experiment"""

bins = []
start_count = 0
for i in range(50, 650, 50):
  bins.append(candidate_sentences['sentence'][start_count:start_count+i])
  start_count += i

df_bins = pd.DataFrame({'size': [], 'accuracy': []})
df_bins

for bin in bins:
  entity_pairs = [get_entities(i) for i in tqdm(bin)]
  relations = [get_relation(i) for i in tqdm(bin)]
  source = [i[0] for i in entity_pairs]
  target = [i[1] for i in entity_pairs]
  kg_df = pd.DataFrame({'source': source, 'target': target, 'edge': relations})
  kg_df = kg_df[kg_df.source != '']
  kg_df = kg_df[kg_df.target != '']
  kg_df = kg_df[kg_df.edge != 'n/a']
  accuracy = (kg_df.shape[0] / len(bin))
  temp = pd.DataFrame({'size':[len(bin)], 'accuracy':[accuracy]})
  df_bins = df_bins.append(temp, ignore_index = True)

df_bins

df_bins.plot(x ='size', y='accuracy', kind = 'line')
plt.show()